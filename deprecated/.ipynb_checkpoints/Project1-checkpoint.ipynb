{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Filter out deprecated warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using data for green cabs, year 2016, February, March and April\n",
    "green2 = pd.read_csv('../raw_data/green_tripdata_2016-02.csv')\n",
    "green3 = pd.read_csv('../raw_data/green_tripdata_2016-03.csv')\n",
    "green4 = pd.read_csv('../raw_data/green_tripdata_2016-04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green1 = pd.read_csv('../raw_data/green_tripdata_2016-01.csv')\n",
    "green5 = pd.read_csv('../raw_data/green_tripdata_2016-05.csv')\n",
    "green6 = pd.read_csv('../raw_data/green_tripdata_2016-06.csv')\n",
    "green7 = pd.read_csv('../raw_data/green_tripdata_2016-07.csv')\n",
    "green8 = pd.read_csv('../raw_data/green_tripdata_2016-08.csv')\n",
    "green9 = pd.read_csv('../raw_data/green_tripdata_2016-09.csv')\n",
    "green10 = pd.read_csv('../raw_data/green_tripdata_2016-10.csv')\n",
    "green11 = pd.read_csv('../raw_data/green_tripdata_2016-11.csv')\n",
    "green12 = pd.read_csv('../raw_data/green_tripdata_2016-12.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine data for green cabs into one dataframe\n",
    "green_cabs = green2.append([green3, green4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_collisions = pd.read_csv('../raw_data/rows.csv?accessType=DOWNLOAD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make all letters in the columns lower-case for consistency\n",
    "green_cabs.columns= green_cabs.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In green_cabs, Ehail_fee consists of only 'nan', therefore should be removed. \n",
    "2. There is 'nan' in trip type, and trip type does not contribute much to our study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = green_cabs.drop(columns=['ehail_fee', 'trip_type '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange columns in both df\n",
    "green_index = ['dropoff_latitude', 'dropoff_longitude', 'pickup_latitude', 'pickup_longitude', 'lpep_dropoff_datetime', 'lpep_pickup_datetime', 'extra', 'fare_amount', 'mta_tax', 'passenger_count', 'payment_type', 'ratecodeid', 'store_and_fwd_flag', 'tip_amount', 'tolls_amount', 'total_amount', 'trip_distance', 'vendorid', 'improvement_surcharge']\n",
    "\n",
    "green_cabs = green_cabs[green_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_boundaries(df):\n",
    "    \"\"\" Make sure that all coordinates are within New York City, \n",
    "        remove those that are not \"\"\"\n",
    "    \n",
    "    MIN_LAT = 40.47739894\n",
    "    MAX_LAT = 40.91617849\n",
    "    MIN_LONG = -74.25909008\n",
    "    MAX_LONG = -73.70018092\n",
    "    \n",
    "    df = df[(df['pickup_latitude'] >= MIN_LAT) & (df['pickup_latitude'] <= MAX_LAT)]\n",
    "    df = df[(df['pickup_longitude'] >= MIN_LONG) & (df['pickup_longitude'] <= MAX_LONG)]\n",
    "    \n",
    "    df = df[(df['dropoff_latitude'] >= MIN_LAT) & (df['dropoff_latitude'] <= MAX_LAT)]\n",
    "    df = df[(df['dropoff_longitude'] >= MIN_LONG) & (df['dropoff_longitude'] <= MAX_LONG)]\n",
    "    \n",
    "    return df\n",
    "\n",
    "green_cabs = set_boundaries(green_cabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These features should not contain negative values\n",
    "positive_features = ['passenger_count', 'trip_distance', 'fare_amount', 'tip_amount', 'tolls_amount', 'total_amount']\n",
    "\n",
    "for feature in positive_features:\n",
    "    green_cabs = green_cabs[green_cabs[feature] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fare amount negative due to refund by the company to the passenger\n",
    "2. 0 trip distance due to booking without attendance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are rows where trip_distance is 0 but fare_amount is not zero. \n",
    "2. There are also rows where the dropoff time is the same as the pickup time, but the trip_distance is not zero <br>\n",
    "These might be caused by a faulty taxi meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def faulty_meters(df):\n",
    "    PICKUP_DATETIME = 5\n",
    "    DROPOFF_DATETIME = 4\n",
    "    \n",
    "    df.iloc[:, PICKUP_DATETIME] = pd.to_datetime(df.iloc[:, PICKUP_DATETIME])\n",
    "    df.iloc[:, DROPOFF_DATETIME] = pd.to_datetime(df.iloc[:, DROPOFF_DATETIME])\n",
    "    \n",
    "    # the meter doesn't move but fare is paid\n",
    "    df2 = df[(df['fare_amount'] != 0) & (df['trip_distance'] == 0.0)]\n",
    "    \n",
    "    # time doesnt change but fare is paid, probably faulty meter\n",
    "    df3 = df[(df.iloc[:, PICKUP_DATETIME] == df.iloc[:, DROPOFF_DATETIME]) & (df['fare_amount'] != 0.0)]\n",
    "    \n",
    "    \n",
    "    new_df = df2.append(df3)\n",
    "    return new_df, df\n",
    "\n",
    "green_faulty_meters, green_cabs = faulty_meters(green_cabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = pd.concat([green_cabs, green_faulty_meters, green_faulty_meters]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = green_cabs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs[['fare_amount', 'trip_distance']].plot.scatter(x='fare_amount',\n",
    "                                                  y='trip_distance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_outlier = green_cabs.index[green_cabs['trip_distance'] > 800].tolist()\n",
    "green_cabs = green_cabs.drop(trip_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs[['fare_amount', 'trip_distance']].plot.scatter(x='fare_amount',\n",
    "                                                  y='trip_distance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs[green_cabs['trip_distance'] > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = green_cabs.drop(2368028)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "green_cabs[['fare_amount', 'trip_distance']].plot.scatter(x='fare_amount',\n",
    "                                                  y='trip_distance')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = green_cabs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = green_cabs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate time into days of the week, hours\n",
    "green_cabs['weekday'] = green_cabs.lpep_pickup_datetime.apply(lambda t: t.weekday())\n",
    "green_cabs['hour'] = green_cabs.lpep_pickup_datetime.apply(lambda t: t.hour)\n",
    "\n",
    "#yellow_cabs['weekday'] = yellow_cabs.tpep_pickup_datetime.apply(lambda t: t.weekday())\n",
    "#yellow_cabs['hour'] = yellow_cabs.tpep_pickup_datetime.apply(lambda t: t.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# sf stands for shape file\n",
    "sf = gpd.read_file(\"../raw_data/taxi_zones/taxi_zones.shp\")\n",
    "zone = pd.read_csv(\"../raw_data/taxi_zones/taxi+_zone_lookup.csv\")\n",
    "\n",
    "# Convert the geometry shaape to to latitude and longitude\n",
    "# Please attribute this if you are using it\n",
    "sf['geometry'] = sf['geometry'].to_crs(\"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "\n",
    "zones = list(sf.borough.unique())\n",
    "zone_dict = {}\n",
    "\n",
    "for area in zones:\n",
    "    locator = Nominatim(user_agent = \"myGeocoder\")\n",
    "    location = locator.geocode(area)\n",
    "    zone_dict[area] = location.raw['boundingbox']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates between JFK Airport pickup and dropoff zone\n",
    "JFK_LAT = 40.644456\n",
    "JFK_LON = -73.782875\n",
    "\n",
    "# Given the distance in metres, calculate the change in degree\n",
    "distance = 10\n",
    "lat_angle = 0.001 * (distance / 2.0) * np.cos(JFK_LAT)\n",
    "lon_angle = 0.001 * (distance / 2.0) * np.cos(JFK_LON)\n",
    "lat_min = str(JFK_LAT + lat_angle)\n",
    "lat_max = str(JFK_LAT - lat_angle)\n",
    "lon_min = str(JFK_LON + lon_angle)\n",
    "lon_max = str(JFK_LON - lon_angle)\n",
    "zone_dict['JFK'] = [lat_min, lat_max, lon_min, lon_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wanted_order = ['JFK', 'EWR', 'Manhattan', 'Staten Island', 'Queens', 'Brooklyn', 'Bronx']\n",
    "\n",
    "zone_dict = {p: zone_dict[p] for p in wanted_order}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zone(df, ride_type):\n",
    "    \"\"\" Find the pickup and dropoff zones based on their latitude and longitude \"\"\"\n",
    "    \n",
    "    zone_list = []\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        \n",
    "        if ride_type == \"\":\n",
    "            lat = df.loc[i, 'LATITUDE']\n",
    "            lon = df.loc[i, 'LONGITUDE']\n",
    "        else: \n",
    "            lat = df.loc[i, ride_type + '_latitude']\n",
    "            lon = df.loc[i, ride_type + '_longitude']\n",
    "\n",
    "        toggle = 1\n",
    "        for zone in zone_dict:\n",
    "\n",
    "            MIN_LAT = float(zone_dict[zone][0])\n",
    "            MAX_LAT = float(zone_dict[zone][1])\n",
    "            MIN_LON = float(zone_dict[zone][2])\n",
    "            MAX_LON = float(zone_dict[zone][3])\n",
    "\n",
    "            if ((MIN_LAT <= lat <= MAX_LAT) & (MIN_LON <= lon <= MAX_LON)):\n",
    "                zone_list.append(zone)\n",
    "                toggle = 0\n",
    "                break\n",
    "        \n",
    "        # insert nan when the coordinate is not in any zone\n",
    "        if toggle:\n",
    "            zone_list.append(np.nan)\n",
    "            \n",
    "    return zone_list\n",
    "\n",
    "green_cabs['pickup_zone'] = find_zone(green_cabs, 'pickup')\n",
    "green_cabs['dropoff_zone'] = find_zone(green_cabs, 'dropoff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# External Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_collisions = traffic_collisions.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
    "collisions_2016 = traffic_collisions[traffic_collisions['CRASH DATE'].str.endswith('2016')]\n",
    "collisions_2016 = collisions_2016[(collisions_2016['CRASH DATE'].str.startswith('02')) | (collisions_2016['CRASH DATE'].str.startswith('03')) | (collisions_2016['CRASH DATE'].str.startswith('04'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select relevant columns\n",
    "wanted = ['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'LONGITUDE', 'LATITUDE',\n",
    "          'NUMBER OF PERSONS INJURED', 'NUMBER OF PERSONS KILLED', \n",
    "          'NUMBER OF PEDESTRIANS INJURED', 'NUMBER OF PEDESTRIANS KILLED', \n",
    "          'NUMBER OF CYCLIST INJURED', 'NUMBER OF CYCLIST KILLED', \n",
    "          'NUMBER OF MOTORIST INJURED', 'NUMBER OF MOTORIST KILLED']\n",
    "\n",
    "collisions = collisions_2016[wanted]\n",
    "collisions = collisions.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan in 'BOROUGHS' with zones\n",
    "collision_zone = find_zone(collisions, \"\")\n",
    "collisions['BOROUGH'] = collision_zone\n",
    "collisions = collisions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set boundaries for collisions_df\n",
    "MIN_LAT = 40.47739894\n",
    "MAX_LAT = 40.91617849\n",
    "MIN_LONG = -74.25909008\n",
    "MAX_LONG = -73.70018092\n",
    "\n",
    "collisions = collisions[(collisions['LATITUDE'] >= MIN_LAT) & (collisions['LATITUDE'] <= MAX_LAT)]\n",
    "collisions = collisions[(collisions['LONGITUDE'] >= MIN_LONG) & (collisions['LONGITUDE'] <= MAX_LONG)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert crash time to datetime\n",
    "collisions['CRASH TIME'] = collisions['CRASH TIME'] + ':00'\n",
    "collisions['DATETIME'] = collisions['CRASH DATE'] + ' ' + collisions['CRASH TIME']\n",
    "collisions['DATETIME'] = pd.to_datetime(collisions['DATETIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assumes an affected time period of 1 hour\n",
    "collisions['ENDTIME'] = collisions['DATETIME'] + pd.Timedelta(hours=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of people killed and injured does not intercept with green_cabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select useful columns and fill NAN with 0s'\n",
    "final_wanted = ['DATETIME', 'ENDTIME', 'BOROUGH']\n",
    "collisions_df = collisions[final_wanted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affected(ori_df, ext_df):\n",
    "    \"\"\" Find rows affected by traffic collisions,\n",
    "        returns two lists,\n",
    "        dropoffs affected and pickups affected \"\"\"\n",
    "    \n",
    "    pickup_time = list(ori_df['lpep_pickup_datetime'])\n",
    "    pickup_zone = list(ori_df['pickup_zone'])\n",
    "    dropoff_time = list(ori_df['lpep_dropoff_datetime'])\n",
    "    dropoff_zone = list(ori_df['dropoff_zone'])\n",
    "    \n",
    "    # use same function to find the affected rows\n",
    "    pickup_affected = drop_pick_affected(ext_df, pickup_zone, pickup_time)\n",
    "    dropoff_affected = drop_pick_affected(ext_df, dropoff_zone, dropoff_time)\n",
    "    \n",
    "    return pickup_affected, dropoff_affected\n",
    "\n",
    "def drop_pick_affected(ext_df, zone, time):\n",
    "    \"\"\" Find affected rows where pickups or dropoffs are affected,\n",
    "        returns a list of affected rows \"\"\"\n",
    "    \n",
    "    affected = []\n",
    "    \n",
    "    crash_time = list(ext_df['DATETIME'])\n",
    "    crash_end = list(ext_df['ENDTIME'])\n",
    "    crash_zone = list(ext_df['BOROUGH'])\n",
    "    \n",
    "    for i in range(len(time)):\n",
    "        \n",
    "        # 1 is given if a row is affected\n",
    "        # 0 when a row is unaffected\n",
    "        affected_bool = 0\n",
    "        \n",
    "        for j in range(len(crash_time)):\n",
    "            \n",
    "            # if time is between crash time and affected period\n",
    "            # and is in the same zone\n",
    "            if (crash_time[j] < time[i] <= crash_end[j]) & (crash_zone[j] == zone[i]):\n",
    "                affected_bool = 1\n",
    "\n",
    "            break\n",
    "            \n",
    "        affected.append(affected_bool)\n",
    "        \n",
    "    return affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_affected, dropoff_affected = affected(green_cabs, collisions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs['pickup_affected_by_collisions'] = pickup_affected\n",
    "green_cabs['dropoff_affected_by_collisions'] = dropoff_affected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs = green_cabs.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Geospatial Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "from bokeh.tile_providers import get_provider\n",
    "\n",
    "# Coordinates\n",
    "PICKUP_COORD = ['pickup_latitude', 'pickup_longitude']\n",
    "DROPOFF_COORD = ['dropoff_latitude', 'dropoff_longitude']\n",
    "\n",
    "# mid_coord = the middle coordinates for the map\n",
    "mid_coord = green_cabs[PICKUP_COORD].describe().loc[[\"50%\"]].values[0]\n",
    "\n",
    "# axis ranges\n",
    "x_Range = [green_cabs['pickup_longitude'].min(), green_cabs['pickup_longitude'].max()]\n",
    "y_Range = [green_cabs['pickup_latitude'].min(), green_cabs['pickup_latitude'].max()]\n",
    "\n",
    "TILE = get_provider(\"STAMEN_TERRAIN_RETINA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyc_m = folium.Map(location=mid_coord, tiles=\"Stamen Terrain\", zoom_start=11)\n",
    "\n",
    "nyc_m.save('../mast30034_2021_s2_project_1-YourTeacher23/plots/folium_nyc.html')\n",
    "\n",
    "nyc_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from bokeh.plotting import figure, show, output_file, save\n",
    "from bokeh.tile_providers import  Vendors\n",
    "from bokeh.models import ColorBar, LinearColorMapper\n",
    "from bokeh.palettes import all_palettes\n",
    "\n",
    "# to display bokeh plots inside jupyter, we need to use output_notebook\n",
    "from bokeh.io import reset_output, output_notebook\n",
    "\n",
    "reset_output()\n",
    "output_notebook()\n",
    "# note below that it says \"BokehJS 1.4.0 successfully loaded.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This code is taken from the Python Stream Workshop Repository, \n",
    "    https://github.com/akiratwang/MAST30034_Python/blob/main/tutorials/Lab1_Python.ipynb \"\"\"\n",
    "\n",
    "def latitude_to_mercator(coords):\n",
    "    \"\"\" Function which converts an array of latitude coordinates \n",
    "        into its mercator coordinate representation \"\"\"\n",
    "    k = 6378137\n",
    "    converted = list()\n",
    "    for lat in coords:\n",
    "        converted.append(np.log(np.tan((90 + lat) * np.pi/360.0)) * k)\n",
    "    return converted\n",
    "\n",
    "def longitude_to_mercator(coords):\n",
    "    \"\"\"\n",
    "    Function which converts an array of longitude coordinates \n",
    "    into its mercator coordinate representation\n",
    "    \"\"\"\n",
    "    k = 6378137\n",
    "    converted = list()\n",
    "    for lon in coords:\n",
    "        converted.append(lon * (k * np.pi/180.0))\n",
    "    return converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mercator(df):\n",
    "    \"\"\" Add mercator columns to dataframe \"\"\"\n",
    "    \n",
    "    df['pickupX'] = df['pickup_longitude'].apply(lambda x: longitude_to_mercator([x])[0])\n",
    "    df['pickupY'] = df['pickup_latitude'].apply(lambda x: latitude_to_mercator([x])[0])\n",
    "    df['dropoffX'] = df['dropoff_longitude'].apply(lambda x: longitude_to_mercator([x])[0])\n",
    "    df['dropoffY'] = df['dropoff_latitude'].apply(lambda x: latitude_to_mercator([x])[0])\n",
    "    \n",
    "    return df\n",
    "\n",
    "green_cabs = convert_mercator(green_cabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import curdoc\n",
    "from bokeh.models import Model\n",
    "\n",
    "def clear_doc(p):\n",
    "    \"\"\" Clears doc memory for plots \"\"\"\n",
    "    curdoc().clear()\n",
    "    for model in p.select({'type': Model}):\n",
    "        prev_doc = model.document\n",
    "        model._document = None\n",
    "        if prev_doc:\n",
    "            prev_doc.remove_root(model)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_map(df, state): \n",
    "    \"\"\" Creates a scatter map \"\"\"\n",
    "    \n",
    "    if state == \"pickup\":\n",
    "        COLOUR = \"white\"\n",
    "        F_COLOUR = \"blue\"\n",
    "    elif state ==\"dropoff\":\n",
    "        COLOUR = \"pink\"\n",
    "        F_COLOUR = \"red\"\n",
    "    else:\n",
    "        COLOUR = \"random\"\n",
    "        F_COLOUR = \"random\"\n",
    "        \n",
    "\n",
    "    m = figure(x_range=longitude_to_mercator(x_Range), y_range=latitude_to_mercator(y_Range),\n",
    "           x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "    m.add_tile(TILE)\n",
    "    m.title.text = state + \" in NYC\"\n",
    "\n",
    "    # for every source value, draw a small circle denoting a pickup\n",
    "    m.circle(x=state + 'X', y=state + 'Y', \n",
    "             size=5, color=COLOUR, fill_color=F_COLOUR, fill_alpha=0.5, \n",
    "             source=df[[state + 'X',state + 'Y']])\n",
    "    \n",
    "    \n",
    "    clear_doc(m)\n",
    "    show(m)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collisions['X'] = collisions['LONGITUDE'].apply(lambda x: longitude_to_mercator([x])[0])\n",
    "collisions['Y'] = collisions['LATITUDE'].apply(lambda x: latitude_to_mercator([x])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = figure(x_range=longitude_to_mercator(x_Range), y_range=latitude_to_mercator(y_Range),\n",
    "       x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "m.add_tile(TILE)\n",
    "m.title.text = \"Collisions in NYC\"\n",
    "\n",
    "# for every source value, draw a small circle denoting a pickup\n",
    "m.circle(x='X', y='Y', \n",
    "         size=5, color='pink', fill_color='red', fill_alpha=0.5, \n",
    "         source=collisions[['X','Y']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_map(df, state, note):\n",
    "    \n",
    "    \"\"\" Creates a cluster map \"\"\"\n",
    "    \n",
    "    # create an interactive geospatial graph\n",
    "    cluster = folium.Map(location=mid_coord, tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "    # use a built-in clustering algorithm to apply markers for hotspots\n",
    "    cluster.add_child(FastMarkerCluster(data=df[[state+\"_latitude\", state+\"_longitude\"]].values))\n",
    "\n",
    "    # visualize the plot \n",
    "    cluster.save('../mast30034_2021_s2_project_1-YourTeacher23/plots/' + note + state + 'Cluster.html')\n",
    "    #cluster\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map(green_cabs, 'dropoff', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map(green_cabs, 'pickup', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an interactive geospatial graph\n",
    "cluster = folium.Map(location=mid_coord, tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "\n",
    "# use a built-in clustering algorithm to apply markers for hotspots\n",
    "cluster.add_child(FastMarkerCluster(data=collisions[[\"LATITUDE\", \"LONGITUDE\"]].values))\n",
    "cluster.save('../mast30034_2021_s2_project_1-YourTeacher23/plots/CollisionsCluster.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heat_map(df, state, note):\n",
    "    \n",
    "    \"\"\" Creates a heatmap \"\"\"\n",
    "    \n",
    "    heatmap = folium.Map(location=mid_coord, tiles=\"Stamen Terrain\", zoom_start=10)\n",
    "    heatmap.add_child(HeatMap(df[[state+\"_latitude\", state+\"_longitude\"]].values, radius=10))\n",
    "\n",
    "    heatmap.save('../mast30034_2021_s2_project_1-YourTeacher23/plots/' + note + state + 'Heatmap.html')\n",
    "    #heatmap\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex_map(df, state, note):\n",
    "    \n",
    "    # create bokeh figure, where x_range and y_range are in mercer\n",
    "    hexmap = figure(x_range=longitude_to_mercator(x_Range), y_range=latitude_to_mercator(y_Range),\n",
    "               x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "    \n",
    "    # add map tile\n",
    "    hexmap.add_tile(TILE)\n",
    "    # change title\n",
    "    hexmap.title.text = note + \" \" + state + \" in NYC\"\n",
    "\n",
    "    palette = all_palettes['Magma'][256][::-1]\n",
    "    color_mapper = LinearColorMapper(palette=palette, low=1, high=1449)\n",
    "    color_bar = ColorBar(color_mapper=color_mapper, label_standoff=12)\n",
    "    r, bins = hexmap.hexbin(x=df[state+'X'], y=df[state+'Y'], size=250, palette=palette)\n",
    "\n",
    "    hexmap.add_layout(color_bar, 'right')\n",
    "\n",
    "    \n",
    "    clear_doc(hexmap)\n",
    "    show(hexmap)\n",
    "    save(hexmap, '../mast30034_2021_s2_project_1-YourTeacher23/plots/' + note + state + 'HexMap.html')\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_map(green_cabs, \"pickup\", \"\")\n",
    "heat_map(green_cabs, \"pickup\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_map(green_cabs, \"pickup\", \"\")\n",
    "hex_map(green_cabs, \"dropoff\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_am = green_cabs[green_cabs['hour'] == 6]\n",
    "eleven_pm  = green_cabs[green_cabs['hour'] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map(six_am, \"pickup\", \"6am\")\n",
    "cluster_map(six_am, \"dropoff\", \"6am\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_map(eleven_pm, \"pickup\", \"11pm\")\n",
    "cluster_map(eleven_pm, \"dropoff\", \"11pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_map(six_am, \"pickup\", \"6am\")\n",
    "hex_map(eleven_pm, \"pickup\", \"11pm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_map(six_am, \"dropoff\", \"6am\")\n",
    "hex_map(eleven_pm, \"dropoff\", \"11pm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The plot shows there are more rides at 11pm than 6am despite the fare per mile being more expensive at 6am than 11pm, this shows that the fare per mile does not affect the number of rides at any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affected_rides = green_cabs[green_cabs['dropoff_affected_by_collisions'] == 1]\n",
    "scatter_map(affected_rides, \"dropoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR_ = [\"passenger_count\", \"trip_distance\", \"fare_amount\", \"extra\", \n",
    " \"mta_tax\", \"tip_amount\", \"tolls_amount\", \"improvement_surcharge\", \"total_amount\",\"weekday\", \"hour\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(green_cabs[CORR_].corr())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average $USD/Mile : {:0.2f}\".format(green_cabs.fare_amount.sum()/green_cabs.trip_distance.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green_cabs['fare/mile'] = green_cabs.fare_amount / green_cabs.trip_distance\n",
    "green_cabs['fare/mile'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display pivot table\n",
    "green_cabs.pivot_table('fare/mile', index='hour').plot(figsize=(14,6))\n",
    "plt.ylabel('Fare $USD / mile');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This plot shows that 0500 and 1600 have higher fare_per_mile, and lowest around midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display pivot table\n",
    "green_cabs.pivot_table('fare/mile', index='weekday').plot(figsize=(14,6))\n",
    "plt.ylabel('Fare $USD / mile');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This shows that weekdays have higher fare_per_mile, peaking at 7.9 on Tuesdays, while weekends have lower fare per mile, with the lowest on Saturdays at a little over 7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_vs_fare = sns.barplot(x=\"pickup_zone\", y=\"fare/mile\", data=green_cabs, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoff_vs_fare = sns.barplot(x=\"dropoff_zone\", y=\"fare/mile\", data=green_cabs, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_collisions_vs_fare = sns.barplot(x=\"pickup_affected_by_collisions\", y=\"fare/mile\", data=green_cabs, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_code_vs_fare = sns.barplot(x=\"ratecodeid\", y=\"fare/mile\", data=green_cabs, ci=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1= Standard rate <br>\n",
    "2=JFK (Airport Fare) <br>\n",
    "3=Newark (Airport Fare) <br>\n",
    "4=Nassau or Westchester (Further from downtown) <br>\n",
    "5=Negotiated fare <br>\n",
    "6=Group ride <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_vs_fare = sns.barplot(x=\"pickup_zone\", y=\"fare/mile\", data=green_cabs, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_per_day = green_cabs.groupby(by=[\"weekday\"]).count()\n",
    "ride_per_day['weekday'] = ride_per_day.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_vs_day = sns.barplot(x=\"weekday\", y=\"pickupX\", data=ride_per_day, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_per_hour = green_cabs.groupby(by=[\"hour\"]).count()\n",
    "ride_per_hour['hour'] = ride_per_hour.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_vs_hour = sns.barplot(x=\"hour\", y=\"pickupX\", data=ride_per_hour, ci=None)\n",
    "rides_vs_hour.figure.savefig('rides_vs_hour.png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ride_zone = green_cabs.groupby(by=[\"pickup_zone\"]).count()\n",
    "ride_zone['zone'] = ride_zone.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides_vs_zone = sns.barplot(x=\"zone\", y=\"pickupX\", data=ride_zone, ci=None)\n",
    "rides_vs_zone.figure.savefig('rides_vs_zone.png',dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COLLISIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crash_day = green_cabs.groupby(by=[\"weekday\"]).sum()\n",
    "crash_day['day'] = crash_day.index\n",
    "# Notice that all collisions happen on Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_vs_day = sns.barplot(x=\"day\", y=\"pickup_affected_by_collisions\", data=crash_day, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_hour = green_cabs.groupby(by=[\"hour\"]).sum()\n",
    "crash_hour['hour'] = crash_hour.index\n",
    "# Notice that all collisions happen around 2pm and 3pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_vs_hour = sns.barplot(x=\"hour\", y=\"pickup_affected_by_collisions\", data=crash_hour, ci=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_zone = green_cabs.groupby(by=[\"pickup_zone\"]).sum()\n",
    "crash_zone['zone'] = crash_zone.index\n",
    "# Note that most collisions happen in Brooklyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crash_vs_zone = sns.barplot(x=\"zone\", y=\"pickup_affected_by_collisions\", data=crash_zone, ci=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Anaconda 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
